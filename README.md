# ğŸ™ï¸ Moshi TTS Voice Training WebUI

Enhanced WebUI for training custom voices with Moshi TTS model, featuring improved voice embedding generation and quality optimization.

## âœ¨ Features

- **ğŸ“ Voice Training**: Train custom voices from audio samples
- **ğŸµ TTS Generation**: Generate speech with trained voices
- **ğŸ”§ Advanced Embedding**: Improved fallback method for better voice quality
- **ğŸ“Š Quality Control**: Automatic validation and optimization
- **ğŸŒ Web Interface**: Easy-to-use Gradio interface

## ğŸš€ Quick Start

### Prerequisites

- Python 3.8+
- CUDA-compatible GPU (recommended)
- 8GB+ RAM

### Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/yourusername/moshi-tts-webui.git
   cd moshi-tts-webui
   ```

2. **Create virtual environment**
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

3. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

4. **Run the WebUI**
   ```bash
   python webui.py
   ```

5. **Open in browser**
   - Navigate to `http://localhost:7860`

## ğŸ¯ Voice Training Guide

### 1. Prepare Audio Files
- **Format**: WAV, MP3, or FLAC
- **Quality**: High quality, clear speech
- **Duration**: 1-30 seconds per file
- **Quantity**: 5-10 different samples recommended
- **Content**: Natural speech, avoid background noise

### 2. Training Process
1. Go to **ğŸ“ Training** â†’ **4ï¸âƒ£ Voice Training**
2. Upload your audio files
3. Set voice name and parameters
4. Click **ğŸš€ Start Training**
5. Wait for completion (usually 1-5 minutes)

### 3. Using Trained Voice
1. Go to **ğŸµ TTS Generation**
2. Select your trained voice
3. Enter text to synthesize
4. Generate and download audio

## ğŸ”§ Technical Improvements

### Enhanced Voice Embedding
- **Multi-frequency analysis** for better voice characteristics
- **Spectral feature extraction** (centroid, rolloff)
- **Temporal feature analysis** (energy, pitch, zero-crossing rate)
- **Advanced normalization** for voice quality preservation

### Quality Optimizations
- **Automatic fallback system** when TTS model fails
- **Audio backend compatibility** (soundfile, wave, torchaudio)
- **Voice characteristic preservation** (gender, tone, clarity)
- **Error handling and recovery**

## ğŸ“ Project Structure

```
moshi-tts-webui/
â”œâ”€â”€ webui.py                 # Main WebUI application
â”œâ”€â”€ training_tools.py        # Voice training utilities
â”œâ”€â”€ official_voice_cloning.py # Voice cloning functions
â”œâ”€â”€ download_voices.py       # Voice model downloader
â”œâ”€â”€ configs/                 # Configuration files
â”œâ”€â”€ scripts/                 # Utility scripts
â”œâ”€â”€ audio/                   # Sample audio files
â””â”€â”€ custom_voices/           # Trained voice outputs
```

## âš™ï¸ Configuration

### Training Parameters
- **Epochs**: Number of training iterations (default: 50)
- **Quality**: Training quality level (high/medium/low)
- **Emotion**: Voice emotion (neutral/happy/sad)

### Audio Settings
- **Sample Rate**: 24kHz (recommended)
- **Channels**: Mono preferred
- **Bit Depth**: 16-bit minimum

## ğŸ› Troubleshooting

### Common Issues

**"TTS model embedding failed"**
- Solution: The improved fallback system will handle this automatically
- Check audio file format and quality

**"Cannot access local variable 'np'"**
- Solution: Fixed in latest version
- Update to latest code

**Poor voice quality**
- Use higher quality audio samples
- Record in quiet environment
- Provide more diverse samples (5-10 files)

**Wrong gender/voice characteristics**
- Ensure audio samples are consistent
- Use clear, unprocessed recordings
- Check sample rate and format

### Performance Tips
- Use GPU for faster training
- Close other applications during training
- Use SSD storage for better I/O performance

## ğŸ¤ Contributing

1. Fork the repository
2. Create feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- [Kyutai](https://github.com/kyutai-labs) for the original Moshi TTS model
- [Gradio](https://gradio.app/) for the web interface framework
- Contributors and testers who helped improve voice quality

## ğŸ“ Support

- **Issues**: [GitHub Issues](https://github.com/yourusername/moshi-tts-webui/issues)
- **Discussions**: [GitHub Discussions](https://github.com/yourusername/moshi-tts-webui/discussions)

---

**â­ Star this repository if you find it useful!**